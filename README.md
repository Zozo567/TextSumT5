# Abstractive Text Summarization using Transfer Learning

This repository contains 2 documents:
- research paper
- implementation of the proposed approaches
 
>Recently, abstractive text summarization has achieved success in switching from linear models via sparse and handcrafted features to nonlinear neural net- work models via dense inputs. This success comes from the application of deep learning models on natural language processing tasks where these models are capable of modeling intricate patterns in data without handcrafted features. In this work, the text summarization problem has been explored using Sequence-to-sequence recurrent neu- ral networks and Transfer Learning with a Unified Text-to-Text Transformer approaches. Experimental results showed that the Transfer Learning-based model achieved considerable improvement for abstractive text summarization.

[Text summarization][textsum] refers to the technique of shortening long pieces of text. The intention is to create a coherent and fluent summary having only the main points outlined in the document.

[textsum]: <https://en.wikipedia.org/wiki/Automatic_summarization>
